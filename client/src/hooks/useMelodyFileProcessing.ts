// ãƒ¡ãƒ­ãƒ‡ã‚£ãƒ¼ç”¨ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å—ã‘å–ã‚Šã€å¿…è¦ã«å¿œã˜ã¦é•·ã•èª¿æ•´ãƒ»ã‚µãƒ¼ãƒãƒ¼é€ä¿¡ãƒ»è§£æã‚’è¡Œã†ã‚«ã‚¹ã‚¿ãƒ ãƒ•ãƒƒã‚¯ã€‚
// pitch_series ã‚’å…ƒã«ãƒ¡ãƒ­ãƒ‡ã‚£ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ç”Ÿæˆã—ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«ä¿å­˜ã™ã‚‹ã€‚
import { useEffect, useState } from "react";
import { useSegment } from "../context/SegmentContext";
import { useBarCount } from "../context/BarCountContext";
import { useTempo } from "../context/TempoContext";
import { useAudioBuffer } from "./useAudioBuffer";

export const useMelodyFileProcessing = (audioBlob: Blob | null, triggerKey?: number, enableTrimming: boolean = false) => {
  const { setMelodySegments, setContextAudioBuffer } = useSegment();
  const { barCount } = useBarCount();
  const { tempo } = useTempo();
  const [trimmedBlob, setTrimmedBlob] = useState<Blob | null>(null);

  // ãƒˆãƒªãƒŸãƒ³ã‚°æ¸ˆã¿Blobã‚’AudioBufferã«å¤‰æ›
  const audioBuffer = useAudioBuffer(trimmedBlob);

  // AudioBuffer ãŒå–å¾—ã§ããŸã‚‰ã€"melody" ã¨ã—ã¦ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«ã‚»ãƒƒãƒˆ
  useEffect(() => {
    if (audioBuffer) {
      setContextAudioBuffer("melody", audioBuffer);
    }
  }, [audioBuffer, setContextAudioBuffer]);

  // audioBlobãŒæŒ‡å®šã•ã‚ŒãŸã¨ãã«å‡¦ç†ã‚’é–‹å§‹
  useEffect(() => {
    if (!audioBlob) {
      console.log("ğŸ” audioBlob ãŒè¨­å®šã•ã‚Œã¦ã„ãªã„ãŸã‚ã€å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚");
      return;
    }

    console.log("ğŸ¬ audioBlob ã®å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™");

    // éŸ³å£°ã®é•·ã•ã‚’ expectedSec ã«åˆã‚ã›ã¦åˆ‡ã‚Šè©°ã‚ or ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã—ã€WebM ã«å†ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
    const adjustAudioLength = async (blob: Blob, expectedSec: number): Promise<Blob> => {
      console.log("â³ éŸ³å£°é•·ã‚’èª¿æ•´ä¸­...");
      const audioCtx = new AudioContext();
      const arrayBuffer = await blob.arrayBuffer();
      const decoded = await audioCtx.decodeAudioData(arrayBuffer);

      const sampleRate = decoded.sampleRate;
      const expectedLength = sampleRate * expectedSec;

      let trimmed: AudioBuffer;
      if (decoded.length > expectedLength) {
        console.log("âœ‚ï¸ éŸ³å£°ã‚’ãƒˆãƒªãƒŸãƒ³ã‚°ã—ã¾ã™");
        trimmed = audioCtx.createBuffer(decoded.numberOfChannels, expectedLength, sampleRate);
        for (let ch = 0; ch < decoded.numberOfChannels; ch++) {
          trimmed.copyToChannel(decoded.getChannelData(ch).slice(0, expectedLength), ch);
        }
      } else {
        console.log("ğŸ“ ç„¡éŸ³ã‚’è¿½åŠ ã—ã¦éŸ³å£°ã‚’ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã—ã¾ã™");
        trimmed = audioCtx.createBuffer(decoded.numberOfChannels, expectedLength, sampleRate);
        for (let ch = 0; ch < decoded.numberOfChannels; ch++) {
          const sourceData = decoded.getChannelData(ch);
          const paddedData = new Float32Array(expectedLength);
          paddedData.set(sourceData);
          trimmed.copyToChannel(paddedData, ch);
        }
      }

      console.log("ğŸ™ï¸ WebM å½¢å¼ã§å†ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ä¸­...");
      const realCtx = new AudioContext();
      const dest = realCtx.createMediaStreamDestination();
      const src = realCtx.createBufferSource();
      src.buffer = trimmed;
      src.connect(dest);
      src.connect(realCtx.destination);

      const recorder = new MediaRecorder(dest.stream);
      const chunks: Blob[] = [];

      recorder.ondataavailable = (e) => chunks.push(e.data);

      return new Promise((resolve) => {
        recorder.onstop = () => {
          resolve(new Blob(chunks, { type: "audio/webm" }));
        };
        recorder.start();
        src.start();
        setTimeout(() => {
          recorder.stop();
        }, expectedSec * 1000);
      });
    };

    // å…¨ä½“å‡¦ç†ã®ãƒ¡ã‚¤ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ï¼šé•·ã•èª¿æ•´ãƒ»é€ä¿¡ãƒ»ãƒ¬ã‚¹ãƒãƒ³ã‚¹å‡¦ç†
    const process = async () => {
      console.log("ğŸ“ tempo ã¨ barCount ã«åŸºã¥ã„ã¦æƒ³å®šé•·ã‚’è¨ˆç®—ã—ã¾ã™");
      const expectedDuration = (60 / tempo) * 4 * barCount;

      let adjustedBlob: Blob;
      if (enableTrimming) {
        adjustedBlob = await adjustAudioLength(audioBlob, expectedDuration);
      } else {
        adjustedBlob = audioBlob;
      }

      setTrimmedBlob(adjustedBlob);

      console.log("ğŸ“¤ adjustedBlob ã‚’ã‚µãƒ¼ãƒãƒ¼ã«é€ä¿¡ã—ã¾ã™");

      // Blob ãŒå°ã•ã™ãã‚‹å ´åˆã¯ä¸æ­£ã¨ã¿ãªã—ã¦ã‚¹ã‚­ãƒƒãƒ—
      if (adjustedBlob.size < 1000) {
        console.warn("âš ï¸ adjustedBlob ãŒå°ã•ã™ãã‚‹ãŸã‚ã€é€ä¿¡ã‚’ä¸­æ­¢ã—ã¾ã™");
        return;
      }

      const formData = new FormData();
      formData.append("file", adjustedBlob);
      formData.append("tempo", tempo.toString());
      formData.append("bar_count", barCount.toString());

      fetch("${baseUrl}/pitch", {
        method: "POST",
        body: formData,
      })
        .then((res) => {
          console.log("ğŸ“¥ ã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰ã®å¿œç­”ã‚’å—ä¿¡ã—ã¾ã—ãŸ");
          if (!res.ok) throw new Error("ã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼: " + res.status);
          return res.json();
        })
        // pitch_series ã‚’ã‚‚ã¨ã«æ™‚é–“æƒ…å ±ä»˜ãã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ç”Ÿæˆ
        .then((data) => {
          console.log("ğŸ§  pitch_series ã®è§£æçµæœã‚’å‡¦ç†ã—ã¾ã™");
          const totalDuration = (60 / tempo) * 4 * barCount;
          const chunkDuration = totalDuration / data.pitch_series.length;
          const segments = data.pitch_series.map((seg: any, index: number) => {
            const start = chunkDuration * index;
            const end = chunkDuration * (index + 1);
            const note = seg.note ?? (seg.label === 'rest' ? 'rest' : 'error');
            const label = seg.label ?? (note === 'rest' ? 'â€”' : 'error');
            return {
              label,
              note,
              hz: seg.hz,
              start,
              end,
              confidence: seg.confidence,
              rms: seg.rms,
              confidence_rms: seg.confidence_rms,
            };
          });
          setMelodySegments(segments);
        })
        .catch((err) => {
          console.error("âŒ Pitchè§£æã‚¨ãƒ©ãƒ¼:", err);
        });
    };

    process();
  }, [audioBlob, triggerKey]);

  // å¤–éƒ¨ã§å†åˆ©ç”¨ã§ãã‚‹ã‚ˆã†ãƒˆãƒªãƒŸãƒ³ã‚°æ¸ˆã¿Blobã‚’è¿”ã™
  return { trimmedBlob };
};