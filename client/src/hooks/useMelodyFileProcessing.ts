// ãƒ¡ãƒ­ãƒ‡ã‚£ãƒ¼ç”¨ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å—ã‘å–ã‚Šã€å¿…è¦ã«å¿œã˜ã¦é•·ã•èª¿æ•´ãƒ»ã‚µãƒ¼ãƒãƒ¼é€ä¿¡ãƒ»è§£æã‚’è¡Œã†ã‚«ã‚¹ã‚¿ãƒ ãƒ•ãƒƒã‚¯ã€‚
// pitch_series ã‚’å…ƒã«ãƒ¡ãƒ­ãƒ‡ã‚£ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ç”Ÿæˆã—ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«ä¿å­˜ã™ã‚‹ã€‚
import { useEffect, useState } from "react";
import { useSegment } from "../context/SegmentContext";
import { useBarCount } from "../context/BarCountContext";
import { useTempo } from "../context/TempoContext";
import { useAudioBuffer } from "./useAudioBuffer";

// ---- debug flag & memoization (module scope) ----
const DEBUG = false; // true ã«ã™ã‚‹ã¨ãƒ­ã‚°ãŒå‡ºã¾ã™

// ãƒˆãƒªãƒŸãƒ³ã‚°çµæœã‚’ Blob å˜ä½ã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆåŒã˜ Blob + åŒã˜æƒ³å®šé•·ãªã‚‰å†è¨ˆç®—ã—ãªã„ï¼‰
type TrimMemo = { duration: number; trimmed: Blob };
const trimMemo = new WeakMap<Blob, TrimMemo>();

// ã‚µãƒ¼ãƒãƒ¼é€ä¿¡ã¾ã§å®Œäº†ã—ãŸ "å‡¦ç†æ¸ˆã¿" ã®å°ï¼ˆåŒã˜ Blob + åŒã˜æƒ³å®šé•·ãªã‚‰å†é€ã—ãªã„ï¼‰
const processedDuration = new WeakMap<Blob, number>();

export const useMelodyFileProcessing = (audioBlob: Blob | null, triggerKey?: number, enableTrimming: boolean = false) => {
  const { setMelodySegments, setContextAudioBuffer } = useSegment();
  const { barCount } = useBarCount();
  const { tempo } = useTempo();
  const [trimmedBlob, setTrimmedBlob] = useState<Blob | null>(null);

  // ãƒˆãƒªãƒŸãƒ³ã‚°æ¸ˆã¿Blobã‚’AudioBufferã«å¤‰æ›
  const audioBuffer = useAudioBuffer(trimmedBlob);

  // AudioBuffer ãŒå–å¾—ã§ããŸã‚‰ã€"melody" ã¨ã—ã¦ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«ã‚»ãƒƒãƒˆ
  useEffect(() => {
    if (audioBuffer) {
      setContextAudioBuffer("melody", audioBuffer);
    }
  }, [audioBuffer, setContextAudioBuffer]);

  // audioBlobãŒæŒ‡å®šã•ã‚ŒãŸã¨ãã«å‡¦ç†ã‚’é–‹å§‹
  useEffect(() => {
    if (!audioBlob) {
      if (DEBUG) console.log("ğŸ” audioBlob ãŒæœªè¨­å®šã®ãŸã‚ã€å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—");
      return;
    }
    if (DEBUG) console.log("ğŸ¬ audioBlob ã®å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™");

    const controller = new AbortController();
    const { signal } = controller;

    const adjustAudioLength = async (blob: Blob, expectedSec: number): Promise<Blob> => {
      if (DEBUG) console.log("â³ éŸ³å£°é•·ã‚’èª¿æ•´ä¸­...");
      const audioCtx = new AudioContext();
      const arrayBuffer = await blob.arrayBuffer();
      const decoded = await audioCtx.decodeAudioData(arrayBuffer);

      const sampleRate = decoded.sampleRate;
      const expectedLength = sampleRate * expectedSec;

      let trimmed: AudioBuffer;
      if (decoded.length > expectedLength) {
        if (DEBUG) console.log("âœ‚ï¸ éŸ³å£°ã‚’ãƒˆãƒªãƒŸãƒ³ã‚°ã—ã¾ã™");
        trimmed = audioCtx.createBuffer(decoded.numberOfChannels, expectedLength, sampleRate);
        for (let ch = 0; ch < decoded.numberOfChannels; ch++) {
          trimmed.copyToChannel(decoded.getChannelData(ch).slice(0, expectedLength), ch);
        }
      } else {
        if (DEBUG) console.log("ğŸ“ ç„¡éŸ³ã‚’è¿½åŠ ã—ã¦éŸ³å£°ã‚’ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã—ã¾ã™");
        trimmed = audioCtx.createBuffer(decoded.numberOfChannels, expectedLength, sampleRate);
        for (let ch = 0; ch < decoded.numberOfChannels; ch++) {
          const sourceData = decoded.getChannelData(ch);
          const paddedData = new Float32Array(expectedLength);
          paddedData.set(sourceData);
          trimmed.copyToChannel(paddedData, ch);
        }
      }

      if (DEBUG) console.log("ğŸ™ï¸ WebM å½¢å¼ã§å†ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ä¸­...");
      const realCtx = new AudioContext();
      const dest = realCtx.createMediaStreamDestination();
      const src = realCtx.createBufferSource();
      src.buffer = trimmed;
      src.connect(dest);
      src.connect(realCtx.destination);

      const recorder = new MediaRecorder(dest.stream);
      const chunks: Blob[] = [];

      recorder.ondataavailable = (e) => chunks.push(e.data);

      return new Promise((resolve) => {
        recorder.onstop = () => {
          const out = new Blob(chunks, { type: "audio/webm" });
          realCtx.close().catch(() => { });
          audioCtx.close().catch(() => { });
          resolve(out);
        };
        recorder.start();
        src.start();
        setTimeout(() => {
          recorder.stop();
        }, expectedSec * 1000);
      });
    };

    // ã“ã“ã§æƒ³å®šé•·ã‚’ç®—å‡ºã—ã¦ã€åŒä¸€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãªã‚‰å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—
    const expectedDuration = (60 / tempo) * 4 * barCount;

    const already = processedDuration.get(audioBlob);
    if (already !== undefined && Math.abs(already - expectedDuration) < 1e-6) {
      if (DEBUG) console.log("âœ… æ—¢å‡¦ç†ã®ãŸã‚å†é€ãƒ»å†è¨ˆç®—ã‚’ã‚¹ã‚­ãƒƒãƒ—");
      const memo = trimMemo.get(audioBlob);
      if (enableTrimming && memo && Math.abs(memo.duration - expectedDuration) < 1e-6) {
        setTrimmedBlob(memo.trimmed);
      } else if (!enableTrimming) {
        setTrimmedBlob(audioBlob);
      }
      return;
    }

    const process = async () => {
      if (DEBUG) console.log("ğŸ“ tempo ã¨ barCount ã«åŸºã¥ã„ã¦æƒ³å®šé•·ã‚’è¨ˆç®—ã—ã¾ã™");

      let adjustedBlob: Blob;
      if (enableTrimming) {
        adjustedBlob = await adjustAudioLength(audioBlob, expectedDuration);
      } else {
        adjustedBlob = audioBlob;
      }

      if (enableTrimming) {
        trimMemo.set(audioBlob, { duration: expectedDuration, trimmed: adjustedBlob });
      }
      processedDuration.set(audioBlob, expectedDuration);

      setTrimmedBlob(adjustedBlob);

      if (DEBUG) console.log("ğŸ“¤ adjustedBlob ã‚’ã‚µãƒ¼ãƒãƒ¼ã«é€ä¿¡ã—ã¾ã™");

      // Blob ãŒå°ã•ã™ãã‚‹å ´åˆã¯ä¸æ­£ã¨ã¿ãªã—ã¦ã‚¹ã‚­ãƒƒãƒ—
      if (adjustedBlob.size < 1000) {
        if (DEBUG) console.warn("âš ï¸ adjustedBlob ãŒå°ã•ã™ãã‚‹ãŸã‚ã€é€ä¿¡ã‚’ä¸­æ­¢ã—ã¾ã™");
        return;
      }

      const formData = new FormData();
      formData.append("file", adjustedBlob);
      formData.append("tempo", tempo.toString());
      formData.append("bar_count", barCount.toString());

      fetch("${baseUrl}/pitch", {
        method: "POST",
        body: formData,
        signal,
      })
        .then((res) => {
          if (DEBUG) console.log("ğŸ“¥ ã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰ã®å¿œç­”ã‚’å—ä¿¡ã—ã¾ã—ãŸ");
          if (!res.ok) throw new Error("ã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼: " + res.status);
          return res.json();
        })
        //pitch_series ã‚’ã‚‚ã¨ã«æ™‚é–“æƒ…å ±ä»˜ãã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ç”Ÿæˆ
        .then((data) => {
          if (DEBUG) console.log("ğŸ§  pitch_series ã®è§£æçµæœã‚’å‡¦ç†ã—ã¾ã™");
          const totalDuration = (60 / tempo) * 4 * barCount;
          const chunkDuration = totalDuration / data.pitch_series.length;
          const segments = data.pitch_series.map((seg: any, index: number) => {
            const start = chunkDuration * index;
            const end = chunkDuration * (index + 1);
            const note = seg.note ?? (seg.label === 'rest' ? 'rest' : 'error');
            const label = seg.label ?? (note === 'rest' ? 'â€”' : 'error');
            return {
              label,
              note,
              hz: seg.hz,
              start,
              end,
              confidence: seg.confidence,
              rms: seg.rms,
              confidence_rms: seg.confidence_rms,
            };
          });
          setMelodySegments(segments);
        })
        .catch((err) => {
          if (DEBUG) console.error("âŒ Pitchè§£æã‚¨ãƒ©ãƒ¼:", err);
        });
    };

    process();
    return () => {
      try { controller.abort(); } catch { }
    };
  }, [audioBlob, triggerKey]);

  // å¤–éƒ¨ã§å†åˆ©ç”¨ã§ãã‚‹ã‚ˆã†ãƒˆãƒªãƒŸãƒ³ã‚°æ¸ˆã¿Blobã‚’è¿”ã™
  return { trimmedBlob };
};